name: 'Gemini Run'

on:
  workflow_call:
    inputs:
      command:
        type: 'string'
        description: 'The command to run (e.g., gemini-architect)'
        required: true
      additional_context:
        type: 'string'
        description: 'Any additional context from the request'
        required: false

concurrency:
  group: '${{ github.workflow }}-${{ inputs.command }}-${{ github.event.pull_request.number || github.event.issue.number }}'
  cancel-in-progress: false

defaults:
  run:
    shell: 'bash'

jobs:
  run:
    runs-on: 'ubuntu-latest'
    permissions:
      contents: 'write'
      id-token: 'write'
      issues: 'write'
      pull-requests: 'write'
    steps:
      - name: 'Mint identity token'
        id: 'mint_identity_token'
        if: |-
          ${{ vars.APP_ID }}
        uses: 'actions/create-github-app-token@a8d616148505b5069dccd32f177bb87d7f39123b' # ratchet:actions/create-github-app-token@v2
        with:
          app-id: '${{ vars.APP_ID }}'
          private-key: '${{ secrets.APP_PRIVATE_KEY }}'
          permission-contents: 'write'
          permission-issues: 'write'
          permission-pull-requests: 'write'

      - name: 'Run Gemini CLI'
        id: 'run_gemini'
        uses: 'google-github-actions/run-gemini-cli@v0' # ratchet:exclude
        env:
          TITLE: '${{ github.event.pull_request.title || github.event.issue.title }}'
          DESCRIPTION: '${{ github.event.pull_request.body || github.event.issue.body }}'
          EVENT_NAME: '${{ github.event_name }}'
          GITHUB_TOKEN: '${{ steps.mint_identity_token.outputs.token || secrets.GITHUB_TOKEN || github.token }}'
          IS_PULL_REQUEST: '${{ !!github.event.pull_request }}'
          ISSUE_NUMBER: '${{ github.event.pull_request.number || github.event.issue.number }}'
          REPOSITORY: '${{ github.repository }}'
          ADDITIONAL_CONTEXT: '${{ inputs.additional_context }}'
        with:
          gemini_api_key: '${{ secrets.GEMINI_API_KEY }}'
          gemini_model: 'gemini-2.0-flash-exp'
          use_pnpm: true
          workflow_name: '${{ inputs.command }}'
          settings: |-
            {
              "model": {
                "maxSessionTurns": 30
              },
              "telemetry": {
                "enabled": true,
                "target": "local",
                "outfile": ".gemini/telemetry.log"
              },
              "mcpServers": {
                "github": {
                  "command": "docker",
                  "args": [
                    "run",
                    "-i",
                    "--rm",
                    "-e",
                    "GITHUB_PERSONAL_ACCESS_TOKEN",
                    "ghcr.io/github/github-mcp-server:v0.18.0"
                  ],
                  "includeTools": [
                    "add_issue_comment",
                    "get_issue",
                    "get_issue_comments",
                    "list_issues",
                    "search_issues",
                    "create_pull_request",
                    "pull_request_read",
                    "list_pull_requests",
                    "search_pull_requests",
                    "create_branch",
                    "create_or_update_file",
                    "delete_file",
                    "fork_repository",
                    "get_commit",
                    "get_file_contents",
                    "list_commits",
                    "push_files",
                    "search_code"
                  ],
                  "env": {
                    "GITHUB_PERSONAL_ACCESS_TOKEN": "${GITHUB_TOKEN}"
                  }
                },
                "filesystem": {
                  "command": "npx",
                  "args": ["-y", "@modelcontextprotocol/server-filesystem", "."],
                  "env": {}
                },
                "memory": {
                  "command": "npx",
                  "args": ["-y", "@modelcontextprotocol/server-memory"],
                  "env": {}
                },
                "sequential-thinking": {
                  "command": "npx",
                  "args": ["-y", "@modelcontextprotocol/server-sequential-thinking"],
                  "env": {}
                }
              },
              "tools": {
                "core": [
                  "run_shell_command(cat)",
                  "run_shell_command(echo)",
                  "run_shell_command(grep)",
                  "run_shell_command(head)",
                  "run_shell_command(tail)",
                  "run_shell_command(ls)",
                  "run_shell_command(find)",
                  "run_shell_command(pnpm)"
                ]
              }
            }
          prompt: '/${{ inputs.command }}'
