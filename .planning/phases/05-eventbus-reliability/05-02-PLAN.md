---
phase: 05-eventbus-reliability
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - packages/server/src/events/events.ts
autonomous: true

must_haves:
  truths:
    - "EventBus service emits typed domain events via broadcaster"
    - "Events persist to outbox within transaction scope"
    - "Duplicate events are detected and skipped"
    - "Failed events dead-letter after max retries"
  artifacts:
    - path: "packages/server/src/events/events.ts"
      provides: "EventBus service with emit, subscribe, broadcaster integration"
      min_lines: 200
      contains: "class EventBus"
  key_links:
    - from: "packages/server/src/events/events.ts"
      to: "@effect/cluster"
      via: "Sharding.broadcaster import"
      pattern: "Sharding\\.broadcaster"
    - from: "packages/server/src/events/events.ts"
      to: "@effect/experimental"
      via: "VariantSchema.make import"
      pattern: "VariantSchema\\.make"
    - from: "packages/server/src/events/events.ts"
      to: "packages/database/src/repos.ts"
      via: "DatabaseService for outbox"
      pattern: "DatabaseService"
---

<objective>
EventBus service with typed domain events, transactional outbox, and cluster-wide broadcast.

Purpose: Replace StreamingService.channel() with typed, reliable event publishing. Events emit within database transactions, broadcast across pods via Sharding.broadcaster, deduplicate via PersistedCache, and dead-letter on exhausted retries.

Output:
- Single DomainEvent VariantSchema with order/payment/system/user variants
- EventError with reason discriminant (DeliveryFailed, DuplicateEvent, etc.)
- Polymorphic emit() handling single event or Chunk
- subscribe() with type-safe variant filtering
- Transactional outbox via PersistedQueue integration
</objective>

<execution_context>
@/Users/bardiasamiee/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bardiasamiee/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-eventbus-reliability/05-RESEARCH.md
@.planning/phases/05-eventbus-reliability/05-CONTEXT.md
@.planning/phases/05-eventbus-reliability/05-01-SUMMARY.md
@packages/server/src/infra/cluster.ts
@packages/server/src/infra/jobs.ts
@packages/server/src/observe/metrics.ts
@packages/server/src/utils/resilience.ts
@packages/database/src/repos.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create EventBus service file</name>
  <files>packages/server/src/events/events.ts</files>
  <action>
Create the EventBus service following the research template. The file should be ~250 LOC max.

**Directory:** Create `packages/server/src/events/` directory if it doesn't exist.

**File structure:**

```typescript
/**
 * EventBus: Typed domain events with transactional outbox and cluster broadcast.
 * Single polymorphic VariantSchema - no loose const/type extraction.
 */
import { DeliverAt, RecipientType, Sharding, Snowflake, SqlMessageStorage } from '@effect/cluster';
import { PersistedCache, PersistedQueue, Reactivity, VariantSchema } from '@effect/experimental';
import { Activity, DurableClock, DurableRateLimiter } from '@effect/workflow';
import { Chunk, Clock, DateTime, Duration, Effect, Exit, HashSet, Match, Metric, Option, PrimaryKey, PubSub, Schema as S, Stream } from 'effect';
import { DatabaseService } from '@parametric-portal/database/repos';
import { Context } from '../context.ts';
import { MetricsService } from '../observe/metrics.ts';
import { Telemetry } from '../observe/telemetry.ts';
import { Resilience } from '../utils/resilience.ts';
import { ClusterService } from '../infra/cluster.ts';

// --- [SCHEMA] ----------------------------------------------------------------

// VariantSchema factory: single source for variants, Class, Field
const _VS = VariantSchema.make({ variants: ['order', 'payment', 'system', 'user'] as const, defaultVariant: 'system' });

// Error reason discriminant with Match.type for compile-time exhaustiveness
const EventErrorReason = S.Literal('DeliveryFailed', 'DeserializationFailed', 'DuplicateEvent', 'HandlerMissing', 'HandlerTimeout', 'MaxRetries', 'TransactionRollback', 'ValidationFailed');
const _errorProps = Match.type<typeof EventErrorReason.Type>().pipe(
  Match.when('DeliveryFailed', () => ({ retryable: true, terminal: false })),
  Match.when('DeserializationFailed', () => ({ retryable: false, terminal: true })),
  Match.when('DuplicateEvent', () => ({ retryable: false, terminal: true })),
  Match.when('HandlerMissing', () => ({ retryable: false, terminal: true })),
  Match.when('HandlerTimeout', () => ({ retryable: true, terminal: false })),
  Match.when('MaxRetries', () => ({ retryable: false, terminal: true })),
  Match.when('TransactionRollback', () => ({ retryable: false, terminal: true })),
  Match.when('ValidationFailed', () => ({ retryable: false, terminal: true })),
  Match.exhaustive,
);

class EventError extends S.TaggedError<EventError>()('EventError', {
  cause: S.optional(S.Unknown),
  eventId: S.optional(S.String),
  reason: EventErrorReason,
}) {
  get isTerminal(): boolean { return _errorProps(this.reason).terminal; }
  get isRetryable(): boolean { return _errorProps(this.reason).retryable; }
  static readonly from = (eventId: string, reason: typeof EventErrorReason.Type, cause?: unknown) => new EventError({ cause, eventId, reason });
}

// DomainEvent class via _VS.Class - creates Schema.Class with static variant accessors
class DomainEvent extends _VS.Class('DomainEvent')({
  eventId: S.UUID.pipe(S.brand('EventId')),
  aggregateId: S.String,
  correlationId: S.optional(S.UUID),
  causationId: S.optional(S.UUID),
  // NOTE: No occurredAt field - eventId (Snowflake) contains timestamp via Snowflake.timestamp()
  payload: _VS.Field({
    order: S.Struct({ action: S.Literal('placed', 'shipped', 'delivered', 'cancelled'), orderId: S.UUID, status: S.String, items: S.Array(S.Struct({ sku: S.String, qty: S.Number })) }),
    payment: S.Struct({ action: S.Literal('initiated', 'completed', 'failed', 'refunded'), paymentId: S.UUID, amount: S.Number, currency: S.String }),
    system: S.Struct({ action: S.Literal('started', 'stopped', 'health'), details: S.optional(S.Unknown) }),
    user: S.Struct({ action: S.Literal('created', 'updated', 'deleted'), userId: S.UUID, email: S.optional(S.String), changes: S.optional(S.Unknown) }),
  }),
}) {
  [PrimaryKey.symbol]() { return `event:${this.eventId}`; }
}

// EventEnvelope wraps event with emit timestamp + trace context
class EventEnvelope extends S.Class<EventEnvelope>('EventEnvelope')({
  event: DomainEvent,
  emittedAt: S.DateTimeUtcFromNumber,
  traceContext: S.optional(S.Struct({ traceId: S.String, spanId: S.String, parentSpanId: S.optional(S.String) })),
}) {
  [PrimaryKey.symbol]() { return `envelope:${this.event.eventId}`; }
}

// --- [CONSTANTS] -------------------------------------------------------------

const _CONFIG = {
  batch: { maxSize: 100, window: Duration.millis(50) },
  broadcast: { bulkhead: 5, threshold: 3, timeout: Duration.millis(100) },
  buffer: { capacity: 256, replay: 16 },
  dedupe: { ttl: Duration.minutes(5), inMemoryCapacity: 10000, inMemoryTTL: Duration.minutes(5) },
  rateLimit: { window: Duration.seconds(1), limit: 100, algorithm: 'token-bucket' as const },
  retry: { maxAttempts: 5, timeout: Duration.seconds(30), backoffBase: Duration.millis(100) },
} as const;

// Default handler via Match.type - exhaustive, no dispatch table
const _handleDefault = Match.type<DomainEvent>().pipe(
  Match.tag('order', (e) => Match.value(e.payload.action).pipe(
    Match.when('placed', () => Effect.logInfo('Order placed', { orderId: e.payload.orderId })),
    Match.when('shipped', () => Effect.logInfo('Order shipped', { orderId: e.payload.orderId })),
    Match.when('delivered', () => Effect.logInfo('Order delivered', { orderId: e.payload.orderId })),
    Match.when('cancelled', () => Effect.logInfo('Order cancelled', { orderId: e.payload.orderId })),
    Match.exhaustive,
  )),
  Match.tag('user', (e) => Match.value(e.payload.action).pipe(
    Match.when('created', () => Effect.logInfo('User created', { userId: e.payload.userId })),
    Match.when('updated', () => Effect.logInfo('User updated', { userId: e.payload.userId })),
    Match.when('deleted', () => Effect.logInfo('User deleted', { userId: e.payload.userId })),
    Match.exhaustive,
  )),
  Match.tag('payment', () => Effect.void),
  Match.tag('system', () => Effect.void),
  Match.exhaustive,
);
```

Continue with SERVICE section implementing:

1. **Effect.Service pattern** with dependencies: ClusterService.Layer, DatabaseService.Default, MetricsService.Default, Reactivity.layer, PersistedCache.layer

2. **Scoped effect** that:
   - Gets sharding, db, metrics, reactivity
   - Creates statusHub via PubSub.sliding
   - Creates broadcaster via sharding.broadcaster(RecipientType.Topic('domain-events', EventEnvelope))
   - Creates dedupCache via PersistedCache.make with DedupKey
   - Creates outboxQueue via PersistedQueue.make

3. **_processEnvelope** function wrapping Activity.make for idempotent handling

4. **Outbox worker** with DurableRateLimiter and circuit-protected broadcast

5. **emit()** polymorphic function handling single DomainEvent or Chunk:
   - Uses Match.value to detect Chunk.isChunk
   - Enriches with eventId (Snowflake), correlationId (from Context.Request)
   - Offers to outboxQueue with id for idempotency
   - Publishes to statusHub for local subscribers

6. **subscribe()** returning Stream with type-safe variant filtering

7. **Static exports** in class: Config, Error, Event, Envelope, Topic

8. **Namespace exports** for types: Variant, Event, Envelope, Handler, DedupKey

Pattern: Follow cluster.ts and jobs.ts density - single const + namespace merge, <250 LOC.

CRITICAL: Use Match.type for exhaustive handling, NO dispatch tables, NO ternary for complex branches.
  </action>
  <verify>
1. Run `pnpm exec nx run server:typecheck` - No type errors
2. File is under 250 LOC
3. EventBus exports: emit, subscribe, onEvent methods
4. VariantSchema used with _VS.Class, _VS.Field patterns
5. Match.type used for error props and default handler
  </verify>
  <done>EventBus service implements transactional outbox with cluster broadcast and typed events</done>
</task>

<task type="auto">
  <name>Task 2: Verify metrics integration</name>
  <files>packages/server/src/observe/metrics.ts</files>
  <action>
Verify that metrics.ts already has the events.* metrics needed by EventBus.

Check for existence of:
- events.deadLettered (counter)
- events.deliveryLatency (histogram)
- events.duplicatesSkipped (counter)
- events.emitted (counter)
- events.outboxDepth (gauge)
- events.processed (counter)
- events.retries (counter)
- events.subscriptions (gauge)

If any are missing, add them following the existing pattern.

The research shows metrics.ts already has these defined - just verify they exist at correct paths.
  </action>
  <verify>
1. Check MetricsService.events namespace has all required metrics
2. Run `pnpm exec nx run server:typecheck`
  </verify>
  <done>Event metrics available for EventBus tracking</done>
</task>

</tasks>

<verification>
1. `pnpm exec nx run server:typecheck` - No type errors
2. EventBus service exports emit, subscribe, onEvent
3. DomainEvent uses VariantSchema with order/payment/system/user variants
4. EventError has reason discriminant with isTerminal/isRetryable getters
5. Transactional outbox pattern via PersistedQueue.offer
6. Broadcaster configured for cross-pod fan-out
7. Metrics integration uses events.* counters/gauges
</verification>

<success_criteria>
- EventBus.emit() accepts single DomainEvent or Chunk (polymorphic)
- EventBus.subscribe() returns typed Stream filtered by variant
- Events persist to outbox before broadcast (transactional)
- Duplicate events detected via PersistedCache and skipped
- Failed events dead-letter after configured max retries
- File under 250 LOC with const + namespace merge
</success_criteria>

<output>
After completion, create `.planning/phases/05-eventbus-reliability/05-02-SUMMARY.md`
</output>
