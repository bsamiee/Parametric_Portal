---
phase: 03-singleton-scheduling
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - packages/server/src/infra/cluster.ts
autonomous: true

must_haves:
  truths:
    - "ClusterService.singleton() accepts optional state schema with Ref-based access (run receives stateRef)"
    - "Singleton factories auto-wrap with withinCluster({ isLeader: true })"
    - "Lifecycle hooks onBecomeLeader and onLoseLeadership execute at appropriate times"
    - "Heartbeat gauge updated after each singleton execution via Clock.currentTimeMillis"
    - "State decode errors are caught and mapped to SingletonError.fromSchemaDecode"
    - "Telemetry.span({ metrics: false }) + MetricsService.trackEffect pattern for custom labels"
    - "FiberMap tracks fibers with auto-cleanup on scope close (GROUP3 pattern)"
    - "Effect.raceFirst + sharding.isShutdown coordinates graceful shutdown"
    - "Exit.isInterrupted + Boolean.match distinguishes shutdown from failure"
    - "State auto-persists on scope close via Effect.addFinalizer"
  artifacts:
    - path: "packages/server/src/infra/cluster.ts"
      provides: "Extended singleton and cron factory methods with stateful persistence"
      contains: "onBecomeLeader"
  key_links:
    - from: "packages/server/src/infra/cluster.ts"
      to: "@effect/platform"
      via: "KeyValueStore.SchemaStore for typed state access"
      pattern: "KeyValueStore\\.SchemaStore"
    - from: "packages/server/src/infra/cluster.ts"
      to: "@effect/cluster"
      via: "Sharding.isShutdown for graceful shutdown"
      pattern: "sharding\\.isShutdown"
    - from: "packages/server/src/infra/cluster.ts"
      to: "packages/server/src/context.ts"
      via: "Context.Request.withinCluster"
      pattern: "withinCluster.*isLeader"
    - from: "packages/server/src/infra/cluster.ts"
      to: "packages/server/src/observe/metrics.ts"
      via: "MetricsService.trackEffect"
      pattern: "MetricsService\\.trackEffect"
    - from: "packages/server/src/infra/cluster.ts"
      to: "effect"
      via: "FiberMap, Exit for fiber tracking and shutdown detection"
      pattern: "FiberMap\\.make|Exit\\.isInterrupted"
    - from: "packages/server/src/infra/cluster.ts"
      to: "effect"
      via: "Metric for gauge/counter updates"
      pattern: "Metric\\.set|Metric\\.increment"
---

<objective>
Extend ClusterService.singleton() and ClusterService.cron() factories with state persistence, lifecycle hooks, and automatic withinCluster context wrapping.

Purpose: Enable stateful singletons that persist across leader migrations with proper observability.
Output: Enhanced singleton/cron factories with state schema, lifecycle hooks, MetricsService.trackEffect integration.

**Scope note**: 3 tasks in single file is intentional — singleton factory, cron factory, and exports are tightly coupled (share lifecycle/metrics patterns). Splitting would require cross-task coordination and duplicate wiring. All tasks modify the same static class methods.
</objective>

<execution_context>
@/Users/bardiasamiee/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bardiasamiee/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-singleton-scheduling/03-RESEARCH.md
@.planning/phases/03-singleton-scheduling/03-01-SUMMARY.md
@packages/server/src/infra/cluster.ts
@packages/server/src/context.ts
@packages/server/src/observe/metrics.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend ClusterService.singleton() factory with state and lifecycle hooks</name>
  <files>packages/server/src/infra/cluster.ts</files>
  <action>
Replace existing `ClusterService.singleton` static method with enhanced version.

**IMPORTS** (add to existing imports):
```typescript
// Add Context import:
import { Context } from '../context.ts';

// Add Sharding for isShutdown detection:
import { Sharding } from '@effect/cluster';

// Consolidated effect import (Metric, FiberMap, Exit added for GROUP3 patterns):
import { Array as A, Boolean as B, Cause, Chunk, Clock, Config, Data, Duration, Effect, Exit, FiberMap, Layer, Match, Metric, Number as N, Option, Ref, Schedule, Schema as S } from 'effect';
```

**Singleton Factory** (replace existing static method):
```typescript
static readonly singleton = <E, R, StateSchema extends S.Schema.Any = never>(
  name: string,
  run: (stateRef: Ref.Ref<S.Schema.Type<StateSchema>>) => Effect.Effect<void, E, R>,
  options?: {
    readonly shardGroup?: string;
    readonly state?: { readonly schema: StateSchema; readonly initial: S.Schema.Type<StateSchema> };
    readonly onBecomeLeader?: Effect.Effect<void, never, R>;
    readonly onLoseLeadership?: Effect.Effect<void, never, R>;
  },
) => {
  // State key: namespaced with _CONFIG.singleton.keyPrefix
  const stateKey = `${_CONFIG.singleton.keyPrefix}${name}`;

  return Singleton.make(
    name,
    Effect.gen(function* () {
      const metrics = yield* MetricsService;
      const sharding = yield* Sharding.Sharding;
      yield* Effect.annotateLogsScoped({ 'service.name': `singleton.${name}` });

      // FiberMap for fiber tracking with auto-cleanup (GROUP3 pattern)
      const fibers = yield* FiberMap.make<string>();

      // Lifecycle hooks with finalizer — Telemetry.span wraps entire singleton work below
      yield* options?.onBecomeLeader ?? Effect.void;
      yield* Effect.addFinalizer(() => options?.onLoseLeadership ?? Effect.void);

      // Heartbeat update: Clock.currentTimeMillis for testability (GROUP1 pattern)
      const updateHeartbeat = Clock.currentTimeMillis.pipe(
        Effect.tap((ts) => Metric.set(metrics.singleton.lastExecution, ts)),
        Effect.tap(() => Metric.increment(metrics.singleton.executions)),
      );

      // State initialization: load from KV store or use initial
      const stateRef = yield* (options?.state
        ? Effect.gen(function* () {
            const kv = yield* KeyValueStore.KeyValueStore;
            const store = kv.forSchema(options.state!.schema);
            // Load state with error mapping (GROUP2: Effect.catchTags)
            const loaded = yield* store.get(stateKey).pipe(
              Effect.catchTags({
                PlatformError: (e) => Effect.fail(SingletonError.fromStateLoad(name, e)),
                ParseError: (e) => Effect.fail(SingletonError.fromSchemaDecode(name, e)),
              }),
              Effect.orElseSucceed(() => options.state!.initial),
            );
            const ref = yield* Ref.make(loaded);
            // Auto-persist on scope close
            yield* Effect.addFinalizer(() =>
              Ref.get(ref).pipe(
                Effect.flatMap((state) => store.set(stateKey, state)),
                Effect.catchTag('PlatformError', (e) => Effect.fail(SingletonError.fromStatePersist(name, e))),
                Effect.catchAllCause((cause) => Effect.logError('State persist failed on shutdown', { cause })),
              ),
            );
            return ref;
          })
        : Ref.make(undefined as unknown as S.Schema.Type<StateSchema>));

      // Shutdown detection: Effect.raceFirst + Effect.repeatWhile (GROUP2 pattern)
      const awaitShutdown = sharding.isShutdown.pipe(
        Effect.repeatWhile((shutdown) => !shutdown),
        Effect.tap(() => Effect.logInfo(`Singleton ${name} detected shutdown`)),
      );

      // Main work wrapped with context and metrics
      const mainWork = Context.Request.withinCluster({ isLeader: true })(
        Telemetry.span(run(stateRef), `singleton.${name}`, { metrics: false }).pipe(
          MetricsService.trackEffect({
            duration: metrics.singleton.duration,
            errors: metrics.errors,
            labels: MetricsService.label({ singleton: name }),
          }),
          Effect.tap(() => updateHeartbeat),
        ),
      );

      // Run with shutdown coordination via FiberMap
      yield* FiberMap.run(fibers, 'main-work')(mainWork);

      // Race work against shutdown signal
      const exit = yield* Effect.raceFirst(Effect.never, awaitShutdown).pipe(Effect.exit);

      // Exit.isInterrupted distinguishes graceful shutdown from failure (GROUP2 pattern)
      yield* Boolean.match(Exit.isInterrupted(exit), {
        onTrue: () => Effect.logInfo(`Singleton ${name} interrupted gracefully`),
        onFalse: () => Effect.logWarning(`Singleton ${name} exited unexpectedly`),
      });
    }),
    { shardGroup: options?.shardGroup },
  ).pipe(
    Layer.provide(_clusterLayer),
    Layer.provide(_kvStoreLayers),
  );
};
```

**Key Changes from Existing**:
1. `run` signature changed to `(stateRef: Ref.Ref<State>) => Effect` — State passed via Ref for user modification
2. `options.state` — Typed state persistence via KeyValueStore.forSchema with auto-persist on scope close
3. `options.onBecomeLeader` / `onLoseLeadership` — Lifecycle hooks with finalizer
4. `Context.Request.withinCluster({ isLeader: true })` — Cluster context wrapping
5. `MetricsService.trackEffect` — Unified duration/error tracking
6. `Clock.currentTimeMillis` — Effect-native time for heartbeat (testable via Clock layer)
7. `Effect.catchTags` — Multi-error mapping to SingletonError (GROUP2 pattern)
8. `Telemetry.span({ metrics: false })` — Named tracing (codebase pattern, NOT Effect.fn)
9. `FiberMap` — Fiber tracking with auto-cleanup on scope close (GROUP3 pattern)
10. `Effect.raceFirst` + `sharding.isShutdown` — Graceful shutdown coordination
11. `Exit.isInterrupted` + `Boolean.match` — Distinguish graceful shutdown from failure (GROUP2 patterns)
12. `Effect.addFinalizer` on stateRef — Auto-persist state on scope close (handles shutdown)
13. `_CONFIG.singleton.keyPrefix` — Namespaced state keys

**CRITICAL State Flow**:
- State loaded on startup → Ref created → passed to `run` → user modifies via `Ref.set`/`Ref.update`
- State auto-persists on scope close (graceful shutdown or migration)
- For periodic persistence during long runs, user's `run` should call store.set explicitly
  </action>
  <verify>
`grep -n "onBecomeLeader" packages/server/src/infra/cluster.ts` shows option exists.
`grep -n "withinCluster.*isLeader" packages/server/src/infra/cluster.ts` shows context wrapping.
`grep -n "Effect.never" packages/server/src/infra/cluster.ts` shows singleton stays alive.
`grep -n "Effect.catchTags" packages/server/src/infra/cluster.ts` shows error mapping.
`grep -n "SingletonError.fromStateLoad" packages/server/src/infra/cluster.ts` shows error factory usage.
  </verify>
  <done>
ClusterService.singleton() accepts state schema, lifecycle hooks, auto-wraps with withinCluster({ isLeader: true }), and maps state errors to SingletonError.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend ClusterService.cron() factory with MetricsService.trackEffect</name>
  <files>packages/server/src/infra/cluster.ts</files>
  <action>
Replace existing `ClusterService.cron` static method with enhanced version:

```typescript
static readonly cron = <E, R>(config: {
  readonly name: string;
  readonly cron: Parameters<typeof ClusterCron.make>[0]['cron'];
  readonly execute: Effect.Effect<void, E, R>;
  readonly shardGroup?: string;
  readonly skipIfOlderThan?: Duration.DurationInput;
  readonly calculateNextRunFromPrevious?: boolean;
}) =>
  ClusterCron.make({
    cron: config.cron,
    calculateNextRunFromPrevious: config.calculateNextRunFromPrevious ?? false,
    execute: Effect.gen(function* () {
      const metrics = yield* MetricsService;
      yield* Effect.annotateLogsScoped({ 'service.name': `cron.${config.name}` });

      // Heartbeat update: Clock.currentTimeMillis for testability
      const updateHeartbeat = Clock.currentTimeMillis.pipe(
        Effect.tap((ts) => Metric.set(metrics.singleton.lastExecution, ts)),
        Effect.tap(() => Metric.increment(metrics.singleton.executions)),
      );

      // Execute within cluster context with trackEffect
      // Telemetry.span({ metrics: false }) + MetricsService.trackEffect for custom labels (codebase pattern)
      yield* Context.Request.withinCluster({ isLeader: true })(
        Telemetry.span(config.execute, `cron.${config.name}`, { metrics: false }).pipe(
          MetricsService.trackEffect({
            duration: metrics.singleton.duration,
            errors: metrics.errors,
            labels: MetricsService.label({ singleton: config.name, type: 'cron' }),
          }),
          Effect.tap(() => updateHeartbeat),
        ),
      );
    }),
    name: config.name,
    shardGroup: config.shardGroup,
    skipIfOlderThan: config.skipIfOlderThan ?? _CONFIG.cron.skipIfOlderThan,
  }).pipe(Layer.provide(_clusterLayer));
```

**Key Changes from Existing**:
1. `Context.Request.withinCluster({ isLeader: true })` — Cluster context wrapping
2. `Telemetry.span({ metrics: false })` + `MetricsService.trackEffect` — Matches codebase pattern for custom labels
3. `Clock.currentTimeMillis` — Effect-native time for heartbeat (testable)
4. `Metric.set` / `Metric.increment` — Heartbeat gauge and execution counter
5. `type: 'cron'` label — Distinguishes cron metrics from singleton metrics
6. `calculateNextRunFromPrevious` option — Exposed for user control (research finding)
7. `Effect.gen` used directly — Matches codebase pattern (no Effect.fn usage in codebase)

**NOTE**: Cron jobs do NOT use KeyValueStore by default (stateless). If cron needs state, use ClusterService.singleton with appropriate schedule instead.
  </action>
  <verify>
`grep -n "type: 'cron'" packages/server/src/infra/cluster.ts` shows cron label.
`grep -n "skipIfOlderThan" packages/server/src/infra/cluster.ts` shows config option.
`grep -n "calculateNextRunFromPrevious" packages/server/src/infra/cluster.ts` shows option.
  </verify>
  <done>
ClusterService.cron() uses MetricsService.trackEffect, withinCluster context, heartbeat updates, and Telemetry.span tracing.
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify singleton/cron factory integration and typecheck</name>
  <files>packages/server/src/infra/cluster.ts</files>
  <action>
**NOTE**: SingletonError exports are handled in Plan 01 Task 1. This task verifies integration.

**Verification Steps**:
1. Ensure `Context` import exists from `../context.ts`
2. Ensure `Metric` is in effect imports
3. Verify singleton factory provides both `_clusterLayer` and `_kvStoreLayers`
4. Verify cron factory provides `_clusterLayer`
5. Run typecheck to confirm no type errors

**Static Property Verification** (should exist from Plan 01):
```typescript
static readonly Error = { Cluster: ClusterError, Singleton: SingletonError };
```
  </action>
  <verify>
`grep -n "Context.Request.withinCluster" packages/server/src/infra/cluster.ts` returns 2+ (singleton + cron).
`grep -n "MetricsService.trackEffect" packages/server/src/infra/cluster.ts` returns 2+ (singleton + cron).
`grep -n "Layer.provide(_kvStoreLayers)" packages/server/src/infra/cluster.ts` returns 1+ (singleton only).
`pnpm exec nx run server:typecheck` passes.
  </verify>
  <done>
Singleton and cron factories are integrated with Context, MetricsService, KeyValueStore. Typecheck passes.
  </done>
</task>

</tasks>

<verification>
1. `pnpm exec nx run server:typecheck` passes with no errors
2. `grep -c "withinCluster" packages/server/src/infra/cluster.ts` returns 2+ occurrences (singleton + cron)
3. `grep -c "MetricsService.trackEffect" packages/server/src/infra/cluster.ts` returns 2+ occurrences
4. `grep -c "onBecomeLeader" packages/server/src/infra/cluster.ts` returns 1+ occurrences
5. `grep -c "Telemetry.span" packages/server/src/infra/cluster.ts` returns 3+ occurrences (singleton + cron + existing)
6. `grep -c "SingletonError.from" packages/server/src/infra/cluster.ts` returns 3+ occurrences (error mapping)
7. `grep -c "FiberMap" packages/server/src/infra/cluster.ts` returns 2+ occurrences (make + run)
8. `grep -c "Exit.isInterrupted" packages/server/src/infra/cluster.ts` returns 1+ occurrences (shutdown detection)
9. `grep -c "sharding.isShutdown" packages/server/src/infra/cluster.ts` returns 1+ occurrences (shutdown signal)
10. `grep -c "Effect.raceFirst" packages/server/src/infra/cluster.ts` returns 1+ occurrences (shutdown racing)
</verification>

<success_criteria>
- ClusterService.singleton() accepts optional state schema with Ref-based access pattern
- State loaded on startup, passed to run as Ref, auto-persists on scope close via Effect.addFinalizer
- State errors mapped to SingletonError via Effect.catchTags (GROUP2 pattern)
- Lifecycle hooks (onBecomeLeader, onLoseLeadership) use Effect.addFinalizer
- Both factories auto-wrap with withinCluster({ isLeader: true })
- Telemetry.span({ metrics: false }) + MetricsService.trackEffect pattern for custom labels (codebase pattern)
- Heartbeat gauge updated via Clock.currentTimeMillis (Effect-native, testable)
- FiberMap for fiber tracking with auto-cleanup (GROUP3 pattern)
- Effect.raceFirst + sharding.isShutdown for graceful shutdown coordination
- Exit.isInterrupted + Boolean.match distinguishes graceful shutdown from failure
- Typecheck passes
</success_criteria>

<output>
After completion, create `.planning/phases/03-singleton-scheduling/03-02-SUMMARY.md`
</output>
