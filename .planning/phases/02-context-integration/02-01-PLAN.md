---
phase: 02-context-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/server/src/context.ts
autonomous: true

must_haves:
  truths:
    - "Handler can retrieve cluster state without runtime errors when cluster is available"
    - "Handler receives ClusterError('RunnerUnavailable') when accessing Context.Request.cluster with Option.none() cluster field"
    - "Handler can check leader status via Context.Request.isLeader without errors"
    - "Handler can scope entity operations via withinCluster for proper context isolation"
    - "TypeScript compiles with no errors related to cluster types"
  artifacts:
    - path: "packages/server/src/context.ts"
      provides: "ClusterState interface, cluster field in Data, static accessors"
      contains: "interface ClusterState"
      exports: ["Context"]
  key_links:
    - from: "packages/server/src/context.ts"
      to: "@effect/cluster"
      via: "ShardId import"
      pattern: "import.*ShardId.*from '@effect/cluster'"
    - from: "packages/server/src/context.ts"
      to: "middleware.ts (Plan 02)"
      via: "makeRunnerId export"
      pattern: "static readonly makeRunnerId"
    - from: "packages/server/src/context.ts"
      to: "effect/Function"
      via: "dual import"
      pattern: "import.*dual.*from 'effect/Function'"
---

<objective>
Define ClusterState interface and extend Context.Request with cluster state accessors.

Purpose: Enable handlers to access shard ID, runner ID, and leader status via the existing FiberRef-based context pattern.
Output: Extended context.ts with ClusterState type, branded RunnerId schema, and static accessor methods.
</objective>

<execution_context>
@/Users/bardiasamiee/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bardiasamiee/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-context-integration/02-RESEARCH.md
@.planning/phases/02-context-integration/02-CONTEXT.md
@packages/server/src/context.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add imports, branded schemas, and ClusterState interface</name>
  <files>packages/server/src/context.ts</files>
  <action>
Add imports at top of file (consolidate with existing effect imports):
```typescript
import { ShardId, Snowflake } from '@effect/cluster';
import { dual } from 'effect/Function';
import { ClusterError } from './infra/cluster.js';
```

Add to [SCHEMA] section (after UserRole definition):
```typescript
// Branded types for serialization boundaries
const RunnerId = S.String.pipe(S.pattern(/^\d{18,19}$/), S.brand('RunnerId'));
const ShardIdString = S.String.pipe(S.pattern(/^[a-zA-Z0-9_-]+:\d+$/), S.brand('ShardIdString'));

// Internal helper: Serializable.fromData needs ShardId→string conversion
const _makeShardIdString = (shardId: ShardId): typeof ShardIdString.Type =>
  S.decodeSync(ShardIdString)(shardId.toString());
```

Add new [CLUSTER] section before [SERIALIZABLE]:
```typescript
// --- [CLUSTER] ---------------------------------------------------------------

/** Cluster state: outer Option in Data, inner nulls avoid nesting */
interface ClusterState {
  readonly entityId: string | null;
  readonly entityType: null | string;
  readonly isLeader: boolean;
  readonly runnerId: null | typeof RunnerId.Type;
  readonly shardId: null | ShardId;
}
```

Note: No separate `_clusterDefault` constant — inline the default object in `withinCluster` accessor (Task 2) for single usage site. The `_makeRunnerId` helper is also inlined directly into `Request.makeRunnerId` static method (Task 2) since it's only exposed there.

IMPORTANT: Use official ShardId class from @effect/cluster (implements Equal/Hash). RunnerId as branded string via Schema.
  </action>
  <verify>
```bash
pnpm exec nx run server:typecheck
```
No errors related to ShardId or RunnerId imports.
  </verify>
  <done>ClusterState interface defined with 5 fields. RunnerId/ShardIdString branded schemas defined. _makeShardIdString internal helper for Serializable.</done>
</task>

<task type="auto">
  <name>Task 2: Extend Data interface, _default, namespace, and add accessors</name>
  <files>packages/server/src/context.ts</files>
  <action>
Update Data interface in namespace (add cluster field alphabetically):
```typescript
export interface Data {
  readonly circuit: Option.Option<Circuit>;
  readonly cluster: Option.Option<ClusterState>;  // NEW
  readonly ipAddress: Option.Option<string>;
  readonly rateLimit: Option.Option<RateLimit>;
  readonly requestId: string;
  readonly session: Option.Option<Session>;
  readonly tenantId: string;
  readonly userAgent: Option.Option<string>;
}
```

Update _default constant (add cluster field alphabetically):
```typescript
const _default: Context.Request.Data = {
  circuit: Option.none(),
  cluster: Option.none(),  // NEW
  ipAddress: Option.none(),
  rateLimit: Option.none(),
  requestId: crypto.randomUUID(),
  session: Option.none(),
  tenantId: _Id.default,
  userAgent: Option.none(),
};
```

Update Request.system() method (add cluster field):
```typescript
static readonly system = (requestId = crypto.randomUUID()): Context.Request.Data => ({
  circuit: Option.none(),
  cluster: Option.none(),  // NEW
  ipAddress: Option.none(),
  rateLimit: Option.none(),
  requestId,
  session: Option.none(),
  tenantId: _Id.system,
  userAgent: Option.none(),
});
```

Add static methods to Request class (after toSerializable, before toAttrs):
```typescript
/** Access cluster state, fails with ClusterError('RunnerUnavailable') if not in cluster scope */
static readonly cluster = FiberRef.get(_ref).pipe(
  Effect.flatMap((ctx) => Option.match(ctx.cluster, {
    onNone: () => Effect.fail(new ClusterError({ reason: 'RunnerUnavailable', message: 'Cluster context not available' })),
    onSome: Effect.succeed,
  })),
);

/** Shard ID: Option.none() outside entity scope */
static readonly shardId = FiberRef.get(_ref).pipe(
  Effect.map((ctx) => Option.flatMapNullable(ctx.cluster, (c) => c.shardId)),
);

/** Runner ID: Option.none() outside cluster scope */
static readonly runnerId = FiberRef.get(_ref).pipe(
  Effect.map((ctx) => Option.flatMapNullable(ctx.cluster, (c) => c.runnerId)),
);

/** Leader status: false outside cluster/singleton scope */
static readonly isLeader = FiberRef.get(_ref).pipe(
  Effect.map((ctx) => Option.exists(ctx.cluster, (c) => c.isLeader)),
);

/** Create RunnerId from Snowflake (inlined helper for middleware use) */
static readonly makeRunnerId = (snowflake: Snowflake.Snowflake): typeof RunnerId.Type =>
  S.decodeSync(RunnerId)(Snowflake.toString(snowflake));

/** Run effect with scoped cluster context (dual: data-first and pipeable) */
static readonly withinCluster: {
  <A, E, R>(effect: Effect.Effect<A, E, R>, partial: Partial<ClusterState>): Effect.Effect<A, E, R>;
  (partial: Partial<ClusterState>): <A, E, R>(effect: Effect.Effect<A, E, R>) => Effect.Effect<A, E, R>;
} = dual(2, <A, E, R>(effect: Effect.Effect<A, E, R>, partial: Partial<ClusterState>) =>
  FiberRef.locallyWith(_ref, (ctx) => ({
    ...ctx,
    cluster: Option.some({
      ...Option.getOrElse(ctx.cluster, (): ClusterState => ({ entityId: null, entityType: null, isLeader: false, runnerId: null, shardId: null })),
      ...partial,
    }),
  }))(effect),
);
```

Export types in namespace (add to Context.Request namespace block after Data):
```typescript
export interface ClusterState extends ClusterState {}
export type RunnerId = typeof RunnerId.Type;
```

Note: `dual` import added in Task 1. Namespace exports re-export file-scoped types as `Context.Request.ClusterState` and `Context.Request.RunnerId`. `makeRunnerId` inlined directly — no separate `_makeRunnerId` helper needed.
  </action>
  <verify>
```bash
pnpm exec nx run server:typecheck
```
No errors. Data interface has cluster field. Request class has cluster, shardId, runnerId, isLeader, makeRunnerId, withinCluster static methods.
  </verify>
  <done>Data interface extended with cluster: Option.Option&lt;ClusterState&gt;. Static accessors (cluster, shardId, runnerId, isLeader, makeRunnerId, withinCluster) on Context.Request class.</done>
</task>

</tasks>

<verification>
After both tasks complete:

1. TypeScript compiles without errors:
```bash
pnpm exec nx run server:typecheck
```

2. Verify ClusterState interface exported:
```bash
grep -n "interface ClusterState" packages/server/src/context.ts
```

3. Verify Data interface has cluster field:
```bash
grep -A2 "cluster:" packages/server/src/context.ts | head -5
```

4. Verify static accessors exist:
```bash
grep -E "static readonly (cluster|shardId|runnerId|isLeader|withinCluster)" packages/server/src/context.ts
```
</verification>

<success_criteria>
- ClusterState interface defined with 5 fields: shardId (ShardId | null), runnerId (branded | null), isLeader (boolean), entityType (string | null), entityId (string | null)
- RunnerId branded type schema defined with pattern validation
- ShardIdString branded type schema defined for serialization
- _makeShardIdString internal helper defined (for Serializable.fromData in Plan 02)
- makeRunnerId inlined directly in Request class static method
- Data interface extended with cluster: Option.Option<ClusterState>
- _default and Request.system() include cluster: Option.none()
- Static accessors: cluster (fails if none), shardId (Option), runnerId (Option), isLeader (boolean), makeRunnerId (Snowflake→RunnerId), withinCluster (dual scoped update)
- Namespace exports: Context.Request.ClusterState, Context.Request.RunnerId
- File at ~225 LOC (current 178, adding ~47 lines for types, interfaces, accessors)
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-context-integration/02-01-SUMMARY.md`
</output>
