---
phase: 02-context-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/server/src/context.ts
autonomous: true

must_haves:
  truths:
    - "ClusterState interface defined with shardId, runnerId, isLeader, entityType, entityId"
    - "Handler accesses cluster state via Context.Request.cluster Effect"
    - "Handler accesses isLeader via Context.Request.isLeader Effect"
    - "withinCluster accessor scopes cluster context for entity/singleton handlers"
  artifacts:
    - path: "packages/server/src/context.ts"
      provides: "ClusterState interface, cluster field in Data, static accessors"
      contains: "interface ClusterState"
      exports: ["Context"]
  key_links:
    - from: "packages/server/src/context.ts"
      to: "@effect/cluster"
      via: "ShardId import"
      pattern: "import.*ShardId.*from '@effect/cluster'"
---

<objective>
Define ClusterState interface and extend Context.Request with cluster state accessors.

Purpose: Enable handlers to access shard ID, runner ID, and leader status via the existing FiberRef-based context pattern.
Output: Extended context.ts with ClusterState type, branded RunnerId schema, and static accessor methods.
</objective>

<execution_context>
@/Users/bardiasamiee/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bardiasamiee/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-context-integration/02-RESEARCH.md
@.planning/phases/02-context-integration/02-CONTEXT.md
@packages/server/src/context.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define ClusterState interface and branded types</name>
  <files>packages/server/src/context.ts</files>
  <action>
Add imports at top of file (after existing imports):
```typescript
import { ShardId, Snowflake } from '@effect/cluster';
```

Add to [SCHEMA] section (after UserRole definition):
```typescript
// Branded types for serialization boundaries
const RunnerId = S.String.pipe(S.pattern(/^\d{18,19}$/), S.brand('RunnerId'));
const ShardIdString = S.String.pipe(S.pattern(/^[a-zA-Z0-9_-]+:\d+$/), S.brand('ShardIdString'));

// Trusted internal constructors
const _makeRunnerId = (snowflake: Snowflake.Snowflake): typeof RunnerId.Type =>
  S.decodeSync(RunnerId)(Snowflake.toString(snowflake));

const _makeShardIdString = (shardId: ShardId): typeof ShardIdString.Type =>
  S.decodeSync(ShardIdString)(shardId.toString());
```

Add new [CLUSTER] section before [SERIALIZABLE]:
```typescript
// --- [CLUSTER] ---------------------------------------------------------------

/** Cluster state: outer Option in Data, inner nulls avoid nesting */
interface ClusterState {
  readonly entityId: string | null;
  readonly entityType: string | null;
  readonly isLeader: boolean;
  readonly runnerId: typeof RunnerId.Type | null;
  readonly shardId: ShardId | null;
}

const _clusterDefault: ClusterState = {
  entityId: null,
  entityType: null,
  isLeader: false,
  runnerId: null,
  shardId: null,
};
```

IMPORTANT: Use official ShardId class from @effect/cluster (implements Equal/Hash). RunnerId as branded string via Schema.
  </action>
  <verify>
```bash
pnpm exec nx run server:typecheck
```
No errors related to ShardId or RunnerId imports.
  </verify>
  <done>ClusterState interface defined with all 5 fields (shardId, runnerId, isLeader, entityType, entityId). Branded RunnerId schema and _makeRunnerId constructor exist.</done>
</task>

<task type="auto">
  <name>Task 2: Extend Data interface and add cluster accessors</name>
  <files>packages/server/src/context.ts</files>
  <action>
Update Data interface in namespace (add cluster field alphabetically):
```typescript
export interface Data {
  readonly circuit: Option.Option<Circuit>;
  readonly cluster: Option.Option<ClusterState>;  // NEW
  readonly ipAddress: Option.Option<string>;
  readonly rateLimit: Option.Option<RateLimit>;
  readonly requestId: string;
  readonly session: Option.Option<Session>;
  readonly tenantId: string;
  readonly userAgent: Option.Option<string>;
}
```

Update _default constant (add cluster field):
```typescript
const _default: Context.Request.Data = {
  circuit: Option.none(),
  cluster: Option.none(),  // NEW
  ipAddress: Option.none(),
  rateLimit: Option.none(),
  requestId: crypto.randomUUID(),
  session: Option.none(),
  tenantId: _Id.default,
  userAgent: Option.none(),
};
```

Add static methods to Request class (after existing static methods):
```typescript
/** Access cluster state, fails with die if not in cluster scope */
static readonly cluster = FiberRef.get(_ref).pipe(
  Effect.flatMap((ctx) => Option.match(ctx.cluster, {
    onNone: () => Effect.die('No cluster context - route must be within cluster scope'),
    onSome: Effect.succeed,
  })),
);

/** Shard ID: Option.none() outside entity scope */
static readonly shardId = FiberRef.get(_ref).pipe(
  Effect.map((ctx) => Option.flatMapNullable(ctx.cluster, (c) => c.shardId)),
);

/** Runner ID: Option.none() outside cluster scope */
static readonly runnerId = FiberRef.get(_ref).pipe(
  Effect.map((ctx) => Option.flatMapNullable(ctx.cluster, (c) => c.runnerId)),
);

/** Leader status: false outside cluster/singleton scope */
static readonly isLeader = FiberRef.get(_ref).pipe(
  Effect.map((ctx) => Option.exists(ctx.cluster, (c) => c.isLeader)),
);

/** Run effect with scoped cluster context (dual: data-first and pipeable) */
static readonly withinCluster: {
  <A, E, R>(effect: Effect.Effect<A, E, R>, partial: Partial<ClusterState>): Effect.Effect<A, E, R>;
  (partial: Partial<ClusterState>): <A, E, R>(effect: Effect.Effect<A, E, R>) => Effect.Effect<A, E, R>;
} = dual(2, <A, E, R>(effect: Effect.Effect<A, E, R>, partial: Partial<ClusterState>) =>
  FiberRef.locallyWith(_ref, (ctx) => ({
    ...ctx,
    cluster: Option.some({ ...Option.getOrElse(ctx.cluster, () => _clusterDefault), ...partial }),
  }))(effect),
);
```

Add import for dual:
```typescript
import { dual } from 'effect/Function';
```

Export ClusterState in namespace (add to namespace block):
```typescript
export interface ClusterState extends ClusterState {}
```

Note: The namespace export re-exports the interface defined in file scope, making it accessible as Context.Request.ClusterState.
  </action>
  <verify>
```bash
pnpm exec nx run server:typecheck
```
No errors. Data interface has cluster field. Request class has cluster, shardId, runnerId, isLeader, withinCluster static methods.
  </verify>
  <done>Data interface extended with cluster: Option.Option&lt;ClusterState&gt;. Static accessors (cluster, shardId, runnerId, isLeader, withinCluster) available on Context.Request class.</done>
</task>

</tasks>

<verification>
After both tasks complete:

1. TypeScript compiles without errors:
```bash
pnpm exec nx run server:typecheck
```

2. Verify ClusterState interface exported:
```bash
grep -n "interface ClusterState" packages/server/src/context.ts
```

3. Verify Data interface has cluster field:
```bash
grep -A2 "cluster:" packages/server/src/context.ts | head -5
```

4. Verify static accessors exist:
```bash
grep -E "static readonly (cluster|shardId|runnerId|isLeader|withinCluster)" packages/server/src/context.ts
```
</verification>

<success_criteria>
- ClusterState interface defined with 5 fields: shardId (ShardId | null), runnerId (branded | null), isLeader (boolean), entityType (string | null), entityId (string | null)
- RunnerId branded type schema defined with pattern validation
- ShardIdString branded type schema defined for serialization
- _makeRunnerId and _makeShardIdString constructors defined
- Data interface extended with cluster: Option.Option<ClusterState>
- _default includes cluster: Option.none()
- Static accessors: cluster (fails if none), shardId (Option), runnerId (Option), isLeader (boolean), withinCluster (dual scoped update)
- File under 225 LOC (current ~180, adding ~60 = ~240 - acceptable minor overage for foundation)
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-context-integration/02-01-SUMMARY.md`
</output>
