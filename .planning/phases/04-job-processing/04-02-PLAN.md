---
phase: 04-job-processing
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - packages/server/src/infra/jobs.ts
autonomous: true

must_haves:
  truths:
    - "JobService.submit dispatches to Entity mailbox (no poll loop)"
    - "Job submission to processing latency under 50ms"
    - "JobService interface unchanged for existing callers"
    - "Failed jobs dead-letter to job_dlq after max retries"
    - "No SELECT FOR UPDATE or poll loop in jobs.ts"
    - "File under 225 LOC with const + namespace merge pattern"
  artifacts:
    - path: "packages/server/src/infra/jobs.ts"
      provides: "JobService with Entity-based dispatch"
      contains: "Entity.make"
      min_lines: 100
  key_links:
    - from: "packages/server/src/infra/jobs.ts"
      to: "packages/server/src/infra/cluster.ts"
      via: "ClusterService Layer composition"
      pattern: "Layer\\.provide.*Cluster"
    - from: "packages/server/src/infra/jobs.ts"
      to: "@parametric-portal/database/repos"
      via: "DatabaseService.jobDlq"
      pattern: "db\\.jobDlq"
---

<objective>
Replace poll-based job queue with Entity mailbox dispatch.

Purpose: Eliminate polling latency and DB contention via @effect/cluster Entity pattern. Jobs dispatch instantly via consistent-hash routing to entity mailboxes.
Output: Completely rewritten jobs.ts with JobEntity, JobService facade, preserving existing API.
</objective>

<execution_context>
@/Users/bardiasamiee/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bardiasamiee/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-job-processing/04-RESEARCH.md
@.planning/phases/04-job-processing/04-01-SUMMARY.md
@packages/server/src/infra/jobs.ts
@packages/server/src/infra/cluster.ts
@packages/server/src/observe/metrics.ts
@packages/server/src/context.ts
@packages/server/src/utils/resilience.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define Job schemas, errors, and entity state</name>
  <files>packages/server/src/infra/jobs.ts</files>
  <action>
Replace the entire jobs.ts file with new Entity-based implementation. Start with schema definitions.

**Schema Section:**
```typescript
// --- [SCHEMA] ----------------------------------------------------------------

const JobPriority = S.Literal('critical', 'high', 'normal', 'low');
const JobStatus = S.Literal('queued', 'processing', 'complete', 'failed', 'cancelled');

class JobPayload extends S.Class<JobPayload>('JobPayload')({
  batchId: S.optional(S.String),
  dedupeKey: S.optional(S.String),
  duration: S.optional(S.Literal('short', 'long'), { default: () => 'short' as const }),
  maxAttempts: S.optional(S.Number, { default: () => 3 }),
  payload: S.Unknown,
  priority: S.optional(JobPriority, { default: () => 'normal' as const }),
  type: S.String,
}) {}

class JobStatusResponse extends S.Class<JobStatusResponse>('JobStatusResponse')({
  attempts: S.Number,
  history: S.Array(S.Struct({ error: S.optional(S.String), status: JobStatus, timestamp: S.Number })),
  result: S.optional(S.Unknown),
  status: JobStatus,
}) {}
```

**Errors Section (Data.TaggedError, not Schema.TaggedError - internal errors):**
```typescript
// --- [ERRORS] ----------------------------------------------------------------

class JobError extends Data.TaggedError('JobError')<{
  readonly cause?: unknown;
  readonly jobId?: string;
  readonly reason: 'NotFound' | 'AlreadyCancelled' | 'HandlerMissing' | 'Validation' | 'Processing' | 'MaxRetries' | 'RunnerUnavailable' | 'Timeout';
}> {
  static readonly fromNotFound = (jobId: string) => new JobError({ jobId, reason: 'NotFound' });
  static readonly fromCancelled = (jobId: string) => new JobError({ jobId, reason: 'AlreadyCancelled' });
  static readonly fromHandlerMissing = (jobId: string, type: string) => new JobError({ cause: { type }, jobId, reason: 'HandlerMissing' });
  static readonly fromValidation = (jobId: string, cause: unknown) => new JobError({ cause, jobId, reason: 'Validation' });
  static readonly fromProcessing = (jobId: string, cause: unknown) => new JobError({ cause, jobId, reason: 'Processing' });
  static readonly fromMaxRetries = (jobId: string, cause: unknown) => new JobError({ cause, jobId, reason: 'MaxRetries' });
  static readonly fromRunnerUnavailable = (jobId: string, cause?: unknown) => new JobError({ cause, jobId, reason: 'RunnerUnavailable' });
  static readonly fromTimeout = (jobId: string, cause?: unknown) => new JobError({ cause, jobId, reason: 'Timeout' });
  static readonly _terminal: ReadonlySet<JobError['reason']> = new Set(['Validation', 'HandlerMissing', 'AlreadyCancelled', 'NotFound']);
  static readonly _transient: ReadonlySet<JobError['reason']> = new Set(['Timeout', 'RunnerUnavailable']);
  static readonly isTerminal = (e: JobError): boolean => JobError._terminal.has(e.reason);
  static readonly isTransient = (e: JobError): boolean => JobError._transient.has(e.reason);
}
```

**State Section:**
```typescript
class JobState extends S.Class<JobState>('JobState')({
  attempts: S.Number,
  completedAt: S.optional(S.Number),
  createdAt: S.Number,
  lastError: S.optional(S.String),
  result: S.optional(S.Unknown),
  status: JobStatus,
}) {
  static readonly queued = (ts: number) => new JobState({ attempts: 0, createdAt: ts, status: 'queued' });
  static readonly processing = (state: JobState) => new JobState({ ...state, status: 'processing' });
  static readonly completed = (state: JobState, result: unknown, ts: number) => new JobState({ ...state, completedAt: ts, result, status: 'complete' });
  static readonly failed = (state: JobState, error: string, ts: number) => new JobState({ ...state, attempts: state.attempts + 1, completedAt: ts, lastError: error, status: 'failed' });
  static readonly cancelled = (state: JobState, ts: number) => new JobState({ ...state, completedAt: ts, status: 'cancelled' });
}
```

Imports needed: Entity, Rpc, Sharding from @effect/cluster; Data, Duration, Effect, FiberMap, HashMap, Match, Metric, Option, Ref, Schedule, Schema as S, Clock from effect; Context, MetricsService, DatabaseService, Resilience.
  </action>
  <verify>pnpm exec nx run @parametric-portal/server:typecheck 2>&1 | head -50</verify>
  <done>Schema, error, and state classes defined following research patterns</done>
</task>

<task type="auto">
  <name>Task 2: Implement JobEntity with handlers</name>
  <files>packages/server/src/infra/jobs.ts</files>
  <action>
Add JobEntity definition and layer after the state section.

**Constants Section:**
```typescript
// --- [CONSTANTS] -------------------------------------------------------------

const _CONFIG = {
  entity: { concurrency: 1, mailboxCapacity: 100, maxIdleTime: Duration.minutes(5) },
  pools: { critical: 4, high: 3, normal: 2, low: 1 } as const,
  retry: Schedule.exponential(Duration.millis(100)).pipe(
    Schedule.jittered,
    Schedule.intersect(Schedule.recurs(5)),
    Schedule.upTo(Duration.seconds(30)),
    Schedule.whileInput((e: JobError) => !JobError.isTerminal(e)),
    Schedule.resetAfter(Duration.minutes(5)),
  ),
} as const;
```

**Entity Section:**
```typescript
// --- [ENTITY] ----------------------------------------------------------------

const JobEntity = Entity.make('Job', [
  Rpc.make('submit', {
    error: JobError,
    payload: JobPayload.fields,
    primaryKey: (p) => p.dedupeKey ?? null,
    success: S.Struct({ jobId: S.String, duplicate: S.Boolean }),
  }),
  Rpc.make('status', { payload: S.Struct({ jobId: S.String }), success: JobStatusResponse }),
  Rpc.make('cancel', { error: JobError, payload: S.Struct({ jobId: S.String }), success: S.Void }),
]);
```

**Entity Layer:**
Implement JobEntityLive following ClusterEntityLive pattern from cluster.ts. Key differences:
- Use FiberMap to track running jobs
- Use HashMap Ref for job states
- Use HashMap Ref for handlers
- Process via Context.Request.withinCluster
- Track metrics via MetricsService.trackEffect
- DLQ terminal errors via DatabaseService.jobDlq.insert
- Long jobs call Entity.keepAlive(true/false)

Entity handlers:
- submit: Generate jobId via sharding.getSnowflake, track in FiberMap, increment enqueued metric
- status: Return from jobStates HashMap or default queued state
- cancel: Remove from FiberMap, update state to cancelled

Entity layer options:
- concurrency: 1
- defectRetryPolicy: _CONFIG.retry
- mailboxCapacity: 100
- maxIdleTime: Duration.minutes(5)
- spanAttributes: { 'entity.service': 'job-processing', 'entity.version': 'v1' }
  </action>
  <verify>pnpm exec nx run @parametric-portal/server:typecheck 2>&1 | head -50</verify>
  <done>JobEntity defined with submit/status/cancel RPCs and layer implementation</done>
</task>

<task type="auto">
  <name>Task 3: Implement JobService facade</name>
  <files>packages/server/src/infra/jobs.ts</files>
  <action>
Add JobService Effect.Service as the public API, preserving existing interface for callers.

**Service Section:**
```typescript
// --- [SERVICES] --------------------------------------------------------------

class JobService extends Effect.Service<JobService>()('server/Jobs', {
  dependencies: [JobEntityLive.pipe(Layer.provide(ClusterService.Layer)), DatabaseService.Default, MetricsService.Default],
  scoped: Effect.gen(function* () {
    const sharding = yield* Sharding.Sharding;
    const getClient = yield* sharding.makeClient(JobEntity);
    const handlers = yield* Ref.make(HashMap.empty<string, JobService.Handler>());
    const metrics = yield* MetricsService;
    const db = yield* DatabaseService;

    // Priority routing helper
    const routeByPriority = (jobId: string, p: keyof typeof _CONFIG.pools) => {
      const hash = jobId.split('').reduce((h, c) => (h * 31 + c.charCodeAt(0)) | 0, 0);
      return `job-${p}-${Math.abs(hash) % _CONFIG.pools[p]}`;
    };

    // Polymorphic submit (single or batch)
    const submit = <T>(type: string, payloads: T | readonly T[], opts?: {
      dedupeKey?: string;
      maxAttempts?: number;
      priority?: typeof JobPriority.Type;
    }) => Effect.gen(function* () {
      const items = Array.isArray(payloads) ? payloads : [payloads];
      const priority = opts?.priority ?? 'normal';
      const batchId = items.length > 1 ? crypto.randomUUID() : undefined;
      const results = yield* Effect.forEach(items, (payload, idx) =>
        getClient(routeByPriority(priority, priority)).submit({
          batchId,
          dedupeKey: opts?.dedupeKey ? `${opts.dedupeKey}:${idx}` : undefined,
          maxAttempts: opts?.maxAttempts,
          payload,
          priority,
          type,
        }).pipe(Effect.map((r) => r.jobId)),
        { concurrency: 'unbounded' },
      );
      yield* MetricsService.inc(metrics.jobs.enqueued, MetricsService.label({ priority, type }), items.length);
      return Array.isArray(payloads) ? results : results[0];
    });

    // Alias for backward compat
    const enqueue = submit;

    const replay = (dlqId: string) => Effect.gen(function* () {
      const entry = yield* db.jobDlq.get(dlqId);
      yield* Option.match(entry, {
        onNone: () => Effect.fail(JobError.fromNotFound(dlqId)),
        onSome: (e) => submit(e.type, e.payload, { priority: 'normal' }).pipe(Effect.zipRight(db.jobDlq.markReplayed(dlqId))),
      });
    });

    return {
      cancel: (jobId: string) => getClient(jobId).cancel({ jobId }),
      enqueue,  // Backward compat alias
      registerHandler: <T>(type: string, handler: (payload: T) => Effect.Effect<void, unknown, never>) =>
        Ref.update(handlers, HashMap.set(type, handler as JobService.Handler)),
      replay,
      status: (jobId: string) => getClient(jobId).status({ jobId }),
      submit,
    };
  }),
}) {}
```

**Namespace Section:**
```typescript
// --- [NAMESPACE] -------------------------------------------------------------

namespace JobService {
  export type Handler = (payload: unknown) => Effect.Effect<void, unknown, never>;
  export type Priority = typeof JobPriority.Type;
  export type Status = typeof JobStatus.Type;
  export type Error = InstanceType<typeof JobError>;
}
```

**Export Section:**
```typescript
// --- [EXPORT] ----------------------------------------------------------------

export { JobService };
```

Remove all old code: JOB_TUNING constant, Circuit import, PgClient import, poll loop, semaphore, onStatusChange stream. The new implementation is Entity-only.

NOTE: onStatusChange (pg.listen) is removed. Phase 5 EventBus will provide cross-pod event subscription.
  </action>
  <verify>pnpm exec nx run @parametric-portal/server:typecheck</verify>
  <done>JobService provides submit/enqueue/cancel/status/registerHandler/replay with Entity dispatch; file under 225 LOC</done>
</task>

</tasks>

<verification>
1. `pnpm exec nx run @parametric-portal/server:typecheck` passes
2. No `SELECT FOR UPDATE` or `poll` in jobs.ts: `grep -E 'FOR UPDATE|poll' packages/server/src/infra/jobs.ts` returns empty
3. Entity.make used: `grep 'Entity.make' packages/server/src/infra/jobs.ts` returns line
4. File under 225 LOC: `wc -l packages/server/src/infra/jobs.ts` < 225
5. Export only JobService (no JOB_TUNING)
</verification>

<success_criteria>
- JobEntity with submit/status/cancel RPCs
- JobService facade preserves enqueue/registerHandler interface
- No poll loop, no SELECT FOR UPDATE
- Entity mailbox dispatch with priority routing
- Dead-letter to job_dlq on terminal errors
- File under 225 LOC with const + namespace merge pattern
</success_criteria>

<output>
After completion, create `.planning/phases/04-job-processing/04-02-SUMMARY.md`
</output>
