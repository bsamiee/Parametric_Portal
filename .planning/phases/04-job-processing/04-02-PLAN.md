---
phase: 04-job-processing
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - packages/server/src/infra/jobs.ts
autonomous: true

must_haves:
  truths:
    - "JobService.submit accepts single job or batch array with same function"
    - "JobService.cancel(jobId) interrupts in-flight job via Effect.interrupt"
    - "JobService.status(jobId) returns current state with history"
    - "Priority levels affect processing order via weighted entity routing"
    - "Deduplication works via optional dedupeKey using Rpc.make primaryKey"
    - "Failed jobs dead-letter after configurable max retries"
    - "No poll loop or SELECT FOR UPDATE in jobs.ts"
  artifacts:
    - path: "packages/server/src/infra/jobs.ts"
      provides: "Entity-based JobService with polymorphic submit"
      exports: ["JobService"]
      contains: "Entity.make"
      min_lines: 100
      max_lines: 225
  key_links:
    - from: "packages/server/src/infra/jobs.ts"
      to: "packages/server/src/infra/cluster.ts"
      via: "ClusterService import"
      pattern: "import.*ClusterService.*from.*cluster"
    - from: "packages/server/src/infra/jobs.ts"
      to: "packages/database/src/repos.ts"
      via: "DatabaseService for DLQ"
      pattern: "import.*DatabaseService.*from.*database"
---

<objective>
Gut and replace jobs.ts with Entity-based job dispatch.

Purpose: Replace poll-based job queue with instant Entity mailbox dispatch. Remove SELECT FOR UPDATE patterns. Preserve JobService interface for existing callers.
Output: Complete JobService rewrite under 225 LOC using Entity pattern from Phase 1
</objective>

<execution_context>
@/Users/bardiasamiee/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bardiasamiee/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-job-processing/04-RESEARCH.md
@.planning/phases/04-job-processing/04-CONTEXT.md
@packages/server/src/infra/cluster.ts
@packages/server/src/infra/jobs.ts
@packages/server/src/utils/resilience.ts
@packages/server/src/context.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define JobEntity schemas, errors, and Entity.make</name>
  <files>packages/server/src/infra/jobs.ts</files>
  <action>
Replace the entire file with new Entity-based implementation. Start with schemas and entity definition.

**Section: SCHEMA**
Define typed schemas following Phase 1 ClusterEntity pattern:
- JobPayload: type, payload, priority (optional Literal), dedupeKey (optional), batchId (optional)
- JobStatus: Literal('queued', 'processing', 'complete', 'failed', 'cancelled')
- JobStatusResponse: status, attempts, history array, result (optional)

**Section: ERRORS**
Define JobError as S.TaggedError with reasons:
- NotFound, AlreadyCancelled, HandlerMissing, Validation, Processing
Use static factory methods following ClusterError pattern.

**Section: ENTITY**
Create JobEntity using Entity.make("Job", [...]):
- submit: Rpc.make with primaryKey using dedupeKey (for deduplication)
- status: Rpc.make returning JobStatusResponse
- cancel: Rpc.make with JobError

Use EntityState pattern from cluster.ts but for job-specific state (status, attempts, history).

**Section: CONSTANTS**
Define _CONFIG matching cluster.ts style:
- Priority pool sizing: { critical: 4, high: 3, normal: 2, low: 1 }
- Retry: use Resilience.schedules.default
- maxIdleTime for keepAlive threshold
  </action>
  <verify>Schema definitions compile without errors</verify>
  <done>JobEntity defined with typed RPC messages, JobError with factories</done>
</task>

<task type="auto">
  <name>Task 2: Implement JobEntityLive layer with handler logic</name>
  <files>packages/server/src/infra/jobs.ts</files>
  <action>
Add JobEntityLive layer using Entity.toLayer following cluster.ts pattern.

**Handler implementations:**
1. submit handler:
   - Wrap in Context.Request.withinCluster (from Phase 2 pattern)
   - Get handler from registered handlers Ref
   - Execute handler with proper error handling
   - On failure: check attempts vs maxAttempts
   - If exhausted: dead-letter to db.jobDlq.put
   - Track job state in Ref (queued -> processing -> complete/failed)
   - Use Entity.keepAlive for long jobs (check estimated duration)

2. status handler:
   - Return current state from Ref
   - Include full history array

3. cancel handler:
   - Get fiber from runningJobs Ref
   - Call Fiber.interrupt on running fiber
   - Update state to cancelled

**Entity options:**
- concurrency: 1 (per entity)
- mailboxCapacity: 100
- maxIdleTime: Duration.minutes(5)
- defectRetryPolicy: Schedule.exponential with jitter (from resilience.ts)
- spanAttributes for telemetry

**State tracking:**
- Use Ref.make(HashMap.empty) for job states
- Use Ref.make(HashMap.empty) for running fibers (for cancellation)
- Fork job execution, store fiber reference
  </action>
  <verify>JobEntityLive compiles; no runtime errors in handler stubs</verify>
  <done>JobEntityLive layer processes jobs with proper state tracking and DLQ</done>
</task>

<task type="auto">
  <name>Task 3: Implement JobService facade with priority routing</name>
  <files>packages/server/src/infra/jobs.ts</files>
  <action>
Create JobService class using Effect.Service pattern following cluster.ts.

**Service methods:**
1. submit<T>(type, payloads: T | readonly T[], opts?):
   - Polymorphic: detect array vs single
   - Route to priority-specific entity via routeByPriority
   - Generate batchId for batches
   - Fire-and-forget: return job ID(s) immediately
   - Track metrics: jobs_enqueued_total

2. status(jobId):
   - Route to entity, call status RPC
   - Return JobStatusResponse

3. cancel(jobId):
   - Route to entity, call cancel RPC
   - Return void on success, JobError on failure

4. registerHandler(type, handler):
   - Store in handlers Ref
   - Used by JobEntityLive to dispatch

**Priority routing (Pattern 2 from RESEARCH):**
```typescript
const _pools = { critical: 4, high: 3, normal: 2, low: 1 } as const;
const routeByPriority = (p: keyof typeof _pools) =>
  `job-${p}-${Math.floor(Math.random() * _pools[p])}`;
```

**Dependencies:**
- ClusterService.Layer (provides sharding)
- DatabaseService (for DLQ)
- MetricsService (for job.* metrics)

**Namespace exports:**
- JobService.Handler type
- Remove StatusEvent (no longer using pg.listen)
  </action>
  <verify>`pnpm exec nx run server:typecheck` passes</verify>
  <done>JobService facade provides unchanged interface with Entity-based dispatch</done>
</task>

</tasks>

<verification>
1. `pnpm exec nx run server:typecheck` - Type checking passes
2. File under 225 LOC (count lines)
3. No `SELECT FOR UPDATE` or poll patterns in file
4. No `Schedule.spaced` or `Schedule.repeat` poll loops
5. JobService exports match previous interface (submit, registerHandler)
</verification>

<success_criteria>
- Existing callers using JobService.enqueue still compile (interface unchanged)
- Entity mailbox dispatch replaces poll-based queue
- Priority routing distributes jobs across weighted entity pools
- Deduplication via Rpc.make primaryKey
- DLQ integration for failed jobs
- Cancellation via fiber interruption
- File under 225 LOC
</success_criteria>

<output>
After completion, create `.planning/phases/04-job-processing/04-02-SUMMARY.md`
</output>
