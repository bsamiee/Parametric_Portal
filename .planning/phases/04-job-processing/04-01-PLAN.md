---
phase: 04-job-processing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/database/src/models.ts
  - packages/database/src/repos.ts
  - packages/database/migrations/0002_job_dlq.ts
autonomous: true

must_haves:
  truths:
    - "JobDlq model exists with all required fields for dead-letter tracking"
    - "DatabaseService exposes jobDlq repo methods (insert, get, markReplayed, listPending)"
    - "job_dlq table created with proper indexes and constraints"
  artifacts:
    - path: "packages/database/src/models.ts"
      provides: "JobDlq model class"
      contains: "class JobDlq extends Model.Class"
    - path: "packages/database/src/repos.ts"
      provides: "jobDlq repo methods"
      contains: "jobDlq"
    - path: "packages/database/migrations/0002_job_dlq.ts"
      provides: "SQL migration for job_dlq table"
      contains: "CREATE TABLE job_dlq"
  key_links:
    - from: "packages/database/src/repos.ts"
      to: "packages/database/src/models.ts"
      via: "JobDlq import"
      pattern: "import.*JobDlq"
---

<objective>
Create database infrastructure for job dead-letter queue.

Purpose: Failed jobs need persistent dead-letter storage for debugging, replay, and observability. This is prerequisite for JobEntity implementation.
Output: JobDlq Model.Class, repo methods, SQL migration for job_dlq table.
</objective>

<execution_context>
@/Users/bardiasamiee/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bardiasamiee/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-job-processing/04-RESEARCH.md
@packages/database/src/models.ts
@packages/database/src/repos.ts
@packages/database/migrations/0001_initial.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add JobDlq Model to models.ts</name>
  <files>packages/database/src/models.ts</files>
  <action>
Add JobDlq Model.Class following existing patterns in models.ts. Insert after Job model section.

Model fields (from research):
- id: Model.Generated(S.UUID) — primary key
- originalJobId: S.UUID — link to original job
- appId: S.UUID — tenant scope
- type: S.String — job type
- payload: Model.JsonFromString(S.Unknown) — original payload
- errorReason: S.String — reason discriminant: 'MaxRetries' | 'Validation' | 'HandlerMissing' | 'RunnerUnavailable'
- attempts: S.Number — total attempts before dead-letter
- errorHistory: Model.JsonFromString(S.Array(S.Struct({ error: S.String, timestamp: S.Number }))) — error trail
- dlqAt: Model.DateTimeInsertFromDate — when job was dead-lettered
- replayedAt: Model.FieldOption(S.DateFromSelf) — when job was replayed (null if not replayed)
- requestId: Model.FieldOption(S.UUID) — correlation for cross-pod traces
- userId: Model.FieldOption(S.UUID) — audit trail

Add section header `// --- [JOBS: JOB_DLQ] ---------------------------------------------------------`
Export JobDlq alongside other models in export statement.
  </action>
  <verify>pnpm exec nx run @parametric-portal/database:typecheck</verify>
  <done>JobDlq model class exists with all fields matching research spec; exported from models.ts</done>
</task>

<task type="auto">
  <name>Task 2: Add jobDlq repo methods to DatabaseService</name>
  <files>packages/database/src/repos.ts</files>
  <action>
Add makeJobDlqRepo factory and integrate into DatabaseService.

1. Import JobDlq from models.ts (add to existing import statement)

2. Create makeJobDlqRepo Effect.gen after makeJobRepo:
   ```typescript
   const makeJobDlqRepo = Effect.gen(function* () {
     const r = yield* repo(JobDlq, 'job_dlq', {
       purge: 'purge_job_dlq',
     });
     return {
       ...r,
       get: (id: string) => r.one([{ field: 'id', value: id }]),
       insert: r.insert,
       markReplayed: (id: string) => r.set(id, { replayed_at: Update.now }),
       listPending: (opts?: { type?: string; limit?: number }) => r.find([
         { field: 'replayed_at', op: 'null' },
         ...(opts?.type ? [{ field: 'type', value: opts.type }] : []),
       ], { limit: opts?.limit ?? 100, order: [{ field: 'dlq_at', dir: 'desc' }] }),
     };
   });
   ```

3. Add jobDlq to DatabaseService effect:
   - Add makeJobDlqRepo to Effect.all array
   - Add jobDlq to returned object

Pattern follows existing repos exactly. Use `Update.now` for replayed_at timestamp.
  </action>
  <verify>pnpm exec nx run @parametric-portal/database:typecheck</verify>
  <done>DatabaseService.jobDlq available with get, insert, markReplayed, listPending methods</done>
</task>

<task type="auto">
  <name>Task 3: Create SQL migration for job_dlq table</name>
  <files>packages/database/migrations/0002_job_dlq.ts</files>
  <action>
Create migration file following 0001_initial.ts pattern.

SQL DDL (from research):
```sql
CREATE TABLE job_dlq (
  id UUID PRIMARY KEY DEFAULT uuidv7(),
  original_job_id UUID NOT NULL,
  app_id UUID NOT NULL REFERENCES apps(id) ON DELETE RESTRICT,
  type TEXT NOT NULL,
  payload JSONB NOT NULL,
  error_reason TEXT NOT NULL,
  attempts INTEGER NOT NULL,
  error_history JSONB NOT NULL,
  dlq_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  replayed_at TIMESTAMPTZ,
  request_id UUID,
  user_id UUID,
  CONSTRAINT job_dlq_error_history_array CHECK (jsonb_typeof(error_history) = 'array')
);

-- Indexes
CREATE INDEX idx_job_dlq_type ON job_dlq(type) WHERE replayed_at IS NULL;
CREATE INDEX idx_job_dlq_dlq_at ON job_dlq(dlq_at) WHERE replayed_at IS NULL;
CREATE INDEX idx_job_dlq_request ON job_dlq(request_id) WHERE request_id IS NOT NULL;
CREATE INDEX idx_job_dlq_app_id_fk ON job_dlq(app_id);

-- Trigger for purge
CREATE TRIGGER job_dlq_updated_at BEFORE UPDATE ON job_dlq FOR EACH ROW EXECUTE FUNCTION set_updated_at();

-- Purge function
CREATE OR REPLACE FUNCTION purge_job_dlq(p_older_than_days INT DEFAULT 30)
RETURNS INT LANGUAGE sql AS $$
    WITH purged AS (
        DELETE FROM job_dlq WHERE replayed_at IS NOT NULL
          AND replayed_at < NOW() - (p_older_than_days || ' days')::interval
        RETURNING id
    )
    SELECT COUNT(*)::int FROM purged
$$;
```

Comments:
- Table comment: 'Dead-lettered jobs — use uuid_extract_timestamp(id) for DLQ time'
- error_reason comment: 'Failure classification: MaxRetries, Validation, HandlerMissing, RunnerUnavailable'
- replayed_at comment: 'NULL = pending replay; set when job resubmitted'

Enable RLS on job_dlq table with tenant isolation policy matching jobs table pattern.
  </action>
  <verify>pnpm exec nx run @parametric-portal/database:typecheck</verify>
  <done>Migration file creates job_dlq table with all indexes, constraints, RLS policies</done>
</task>

</tasks>

<verification>
1. `pnpm exec nx run @parametric-portal/database:typecheck` passes
2. JobDlq model exported from models.ts
3. DatabaseService.jobDlq methods available
4. Migration file is valid TypeScript Effect
</verification>

<success_criteria>
- JobDlq model class matches research schema exactly
- Repo provides: get, insert, markReplayed, listPending methods
- SQL migration creates table with proper indexes and RLS
- All typechecks pass
</success_criteria>

<output>
After completion, create `.planning/phases/04-job-processing/04-01-SUMMARY.md`
</output>
