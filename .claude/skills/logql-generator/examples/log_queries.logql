# LogQL Log Query Patterns
# LOC: 131

## === BASIC LOG QUERIES ===
{job="app"} |= "error"
{job="app"} |~ "error|fatal"
{job="app"} |= "error" != "timeout"
{job="nginx"} |~ "HTTP/[0-9.]+ (4|5)[0-9]{2}"

## === PATTERN MATCH (3.0+, 10x faster than regex) ===
{service_name="distributor"} |> "<_> level=debug <_> msg=\"POST /push <_>\""
{service_name="api"} !> "<_> level=debug <_>"
{job="nginx"} |> "<_> \"GET <_>\" 500 <_>"

## === JSON PARSING ===
{app="api"} | json | level="error"
{app="api"} | json | method="POST" | status_code >= 400
{app="api"} | json status, method, duration
{app="api"} | json method="request.method", status="response.status_code"
{app="api"} | json first_server="servers[0]", ua="request.headers[\"User-Agent\"]"
{app="api"} | json | line_format "{{.level}}: {{.message}}"

## === LOGFMT PARSING ===
{app="app"} | logfmt | level="error" | caller="database.go"
{app="api"} | logfmt --strict | __error__ != ""
{app="api"} | logfmt --strict --keep-empty
{app="api"} | logfmt --strict | __error__="" | level="error"

## === PATTERN PARSER / REGEX ===
{job="nginx"} | pattern "<ip> - - [<timestamp>] \"<method> <path> <protocol>\" <status> <size>"
{job="nginx"} | pattern "<ip> - - [<_>] \"<method> <_>\" <status> <_>" | status >= 400
{app="app"} | regexp "(?P<level>\\w+): (?P<message>.+)"

## === DECOLORIZE ===
{app="app"} | decolorize | logfmt | level="error"
{app="app"} | decolorize | json | status >= 500

## === IP FILTERING ===
{job="nginx"} | logfmt | remote_addr = ip("192.168.1.0/24")
{job="nginx"} | logfmt | remote_addr != ip("10.0.0.0/8")
{job="nginx"} | logfmt | remote_addr = ip("192.168.4.5-192.168.4.20")
{job="nginx"} | logfmt | remote_addr = ip("192.168.0.0/16") or remote_addr = ip("10.0.0.0/8")
{job="nginx"} | logfmt | remote_addr = ip("2001:db8::1-2001:db8::8")

## === ADVANCED MULTI-STAGE ===
# Complex multi-condition filter
{app="api"} | json | (status_code >= 400 and status_code < 500) or (status_code >= 500 and duration > 1) | method != "HEAD" | path !~ "/health|/metrics"
# Multi-stage parse + conditional format
{job="nginx"} | pattern "<ip> - - [<timestamp>] \"<method> <path> <_>\" <status> <size>" | json | label_format status_class="{{if ge .status 500}}5xx{{else if ge .status 400}}4xx{{else}}ok{{end}}" | line_format "{{.status_class}}: {{.method}} {{.path}}"

## === UNPACK PARSER ===
{cluster="us-central1", job="myjob"} | unpack
{cluster="us-central1", job="myjob"} | unpack | container="myapp" | json

## === STRUCTURED METADATA (3.0+) ===
{app="api"} | trace_id="abc123"
{app="api"} | trace_id="abc123" | json | level="error"
{app="api"} | user_id="12345" | request_id="req-abc"

## === QUERY ACCELERATION (bloom filters, 3.3+) ===
# ACCELERATED: structured metadata BEFORE parser
{cluster="prod"} | detected_level="error" | json
{cluster="prod"} | detected_level="error" | logfmt
# ACCELERATED: OR filter
{app="api"} | detected_level="error" or detected_level="warn" | json
# NOT ACCELERATED: filter AFTER parser
{cluster="prod"} | json | detected_level="error"

## === TEMPLATE FUNCTIONS ===
# String: replace + truncate + upper
{app="api"} | json | line_format "{{.path | replace \" \" \"_\" | trunc 50 | upper}}"
# Date formatting
{app="api"} | json | line_format "{{__timestamp__ | date \"2006-01-02T15:04:05\"}}: {{.message}}"
# Math: duration conversion
{app="api"} | json | line_format "Duration: {{div .duration_ms 1000}}s"
# Float division
{app="api"} | json | line_format "Duration: {{divf .duration_ns 1000000}}ms"
# Conditional label
{app="api"} | json | label_format severity="{{if ge .status_code 500}}critical{{else if ge .status_code 400}}warning{{else}}info{{end}}"
# Original line access
{app="api"} | json | line_format "ORIGINAL: {{__line__ | lower}}"
# Printf formatting
{app="api"} | json | line_format "{{printf \"%-40.40s\" .request_uri}} {{printf \"%5.5s\" .method}}"
# Iterate JSON array
{job="api"} | json | line_format "{{ range $item := fromJson .items }}{{ $item.name }} {{ end }}"
# Regex replace with capture group
{app="api"} | json | line_format "{{regexReplaceAll \"user_(\\\\d+)\" .message \"User ID: $1\"}}"

## === LABEL OPERATIONS ===
{app="api"} | json | keep namespace, pod, level, message
{app="api"} | json | drop instance, pod
{app="api"} | json | label_format env=`{{.environment}}`, svc=`{{.service}}`

## === PROMTAIL-TO-ALLOY MIGRATION PATTERNS ===
# Promtail is EOL March 2, 2026. Migrate to Alloy using `alloy convert` or rewrite configs.
#
# Promtail scrape_configs -> Alloy loki.source.file + loki.relabel:
#   scrape_configs:                  ->  loki.source.file "logs" {
#     - job_name: app                      targets    = [...]
#       static_configs:                    forward_to = [loki.relabel.app.receiver]
#         - targets: [localhost]          }
#           labels:                       loki.relabel "app" {
#             job: app                      forward_to = [loki.write.default.receiver]
#             __path__: /var/log/*.log      rule { source_labels = ["filename"]
#                                                  target_label  = "job"
#                                                  replacement   = "app" }
#                                         }
#
# Promtail pipeline_stages.json -> Alloy loki.process stage.json:
#   pipeline_stages:                 ->  loki.process "app" {
#     - json:                              forward_to = [loki.write.default.receiver]
#         expressions:                     stage.json { expressions = {"level" = "", "msg" = ""} }
#           level:                         stage.labels { values = {"level" = ""} }
#           msg:                         }
#     - labels:
#         level:
#
# Promtail pipeline_stages.multiline -> Alloy loki.process stage.multiline:
#   pipeline_stages:                 ->  loki.process "multiline" {
#     - multiline:                         forward_to = [loki.write.default.receiver]
#         firstline: '^\d{4}-\d{2}'        stage.multiline {
#         max_lines: 128                     firstline = "^\\d{4}-\\d{2}"
#         max_wait_time: 3s                  max_lines = 128
#                                            max_wait_time = "3s"
#                                          }
#                                        }
#
# Structured metadata (Alloy, replaces custom label extraction for high-cardinality fields):
#   loki.process "structured" {
#     forward_to = [loki.write.default.receiver]
#     stage.json { expressions = {"trace_id" = "", "user_id" = ""} }
#     stage.structured_metadata { values = {"trace_id" = "", "user_id" = ""} }
#   }
# Query: {app="api"} | trace_id="abc123" | json | level="error"
#
# Convert existing Promtail config automatically:
#   alloy convert --source-format=promtail --output=config.alloy promtail.yaml

## === ALLOY NATIVE OTEL PIPELINE (no Promtail equivalent) ===
# Alloy receives OTEL logs natively via otelcol.receiver.otlp:
#   otelcol.receiver.otlp "default" {
#     grpc { endpoint = "0.0.0.0:4317" }
#     http { endpoint = "0.0.0.0:4318" }
#     output { logs = [otelcol.exporter.loki.default.input] }
#   }
#   otelcol.exporter.loki "default" {
#     forward_to = [loki.write.default.receiver]
#   }
# OTEL resource attributes map to structured metadata automatically.
# Query OTEL-sourced logs: {service_name="my-api"} | detected_level="error" | json
